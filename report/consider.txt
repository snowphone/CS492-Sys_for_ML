Write a report of one or two pages long. Your report must include

1. how you implemented (뭔가 중요한 포인트가 더 있다면 적어주시면 됩니다)

  1) open video with openCV

    R/W Video openCV 이용, out video attributes는 reader.get 메소드를 이용하여 최대한 원본을 유지하였으나, 비디오 코덱의 경우 OS마다 기본적으로 지원 가능한 코덱이 다르므로, fourcc는 mp4v를 사용함.

  2) yolov2tiny tensor graph building

    gpu memory 0.7 -> 메모리 터져서 넣어줌. allow_gpu_growth 옵션만으로는 부족하여 추가했다.
    tensorflow를 이용해서, Yolov2tiny의 40layer를 구현하였다. 
    이번 과제는 주어진 weight ndarry 값을 사용하여 weight parameter를 직접 설정하고 inference를 하는것이 목적이므로, 편의성이 강조된 대신 weight값을 변경할 수 없는 tf.contrib 모듈 대신 weight parameter를 manual하게 부여해줄 수 있는 tf.nn 모듈 내의 함수를 사용하였다.
    각 레이어를 생성하는 과정에서 각 레이어에 알맞은 weight 값을 적용하였다. 제공된 pickle 파일에서 kernel은 conv_2d 레이어를, biases는 bias_add 레이어를, (moving_variance, gamma, moving_mean)은 batch_normalization 레이어를 초기화 하는데 사용되었다.

  3) obj detection

    매 loop마다 input frame을 yolov2tiny에 맞게 resize해주고 이를 input으로 inference 한다. Inference된 텐서를 postprocessing 함수에 넣어 bounding box를 추출한다. 이 과정에서 기준값 이하의 confidence 값을 가진 bounding box들은 소거되고, 남은 box들도 non-max-suppression 을 통해 각 object마다 confidence값이 가장 높은 하나의 bounding box만 남겨놓는다.
    box를 원래의 사이즈로 reszie하고 input frame과 합쳐서 output frame을 저장한다. 

2. execution time and how many FPS processed (end-to-end, only for inference)

#1~2에서 시간이 많이 걸리는데 이에대한 이유 서술하면 좋을듯.
why? Due to initializing tensor? 혹은 캐싱?ㅠ

첫 프레임 텐서 저장하는 거 때문에 그런가 했는데 옮겨도 똑같았음.(약간의 차이는 있긴 했지만 메인이 이거 때문이 아님)

       #1      #2     #3   ...
CPU : 0.157  0.083  0.078  ...
GPU : 1.352  0.104  0.011  ...

      total  / Inference(frame) / end-to-end(frame)  /   FPS
CPU : 43.591 /       0.058      /      0.096         /  10.392
GPU : 24.778 /       0.016      /      0.055         /  18.282

Total : 마지막으로 출력되는 값인 줄 알았는데 그거 함수 시간 재는거 였음 여기 total은 end-to-end_sum임 (total/453 = Avg.end-to-end)

위에 값들 몇 번 돌려서 평균값 해야될 것 같음 지금은 그냥 1번 해서 나온 값임

Inference FPS도 필요한지 잘 모르겠네요. lecture #5에 FPS measurement exclusively for DNN computation 라는 말이 있었음.
이후에 FPS improve 하려고하면 resizing part는 어차피 동일 할테니 inference FPS가 더 명확한 수치이기도 한 것 같고..

->결과 분석시 inference FPS간 비교를 해서 inference는 GPU 가속의 힘을 봤지만, postprocessing은 CPU만을 이용하여 sequential하게 구현되었기 때문에 gpu 모드로 동작할 때 병목으로 작용하였다 같은 식으로 서술해보아도 좋지 않을까요? 

3. comparison the execution time from CPU and GPU and analyze it

inference 빼면 시간 비슷하지 않을까 싶음 -> 맞음 비슷함
      end-to-end - inference
CPU :         0.038
GPU :         0.039

GPU using improvement over CPU(문법이 맞나?)
Inference : 3.625x
Total     : 1.760x


The purpose of the report is to show your understanding. Please write the answer short and clear.

Video frame size : 540 x 540
Video fps = 30
Video length = 15s
Video frame number : 453
